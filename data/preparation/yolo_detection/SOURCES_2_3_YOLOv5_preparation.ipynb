{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1j-nLiFhjUO7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "SOURCE2_DIR = '/content/SOURCE2/'\n",
        "SOURCE3_DIR = '/content/SOURCE3/'\n",
        "\n",
        "os.makedirs(SOURCE2_DIR, exist_ok=True)\n",
        "os.makedirs(SOURCE3_DIR, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/Datasets/SOURCE2/detection.zip', 'r') as zf:\n",
        "  zf.extractall(SOURCE2_DIR)\n",
        "\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/Datasets/SOURCE3/detection.zip', 'r') as zf:\n",
        "  zf.extractall(SOURCE3_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "source3_train_pages = [os.path.join(SOURCE3_DIR, 'train', f) for f in os.listdir(os.path.join(SOURCE3_DIR, 'train'))]\n",
        "source3_test_pages = [os.path.join(SOURCE3_DIR, 'test', f) for f in os.listdir(os.path.join(SOURCE3_DIR, 'test'))]\n",
        "source3_validation_pages = [os.path.join(SOURCE3_DIR, 'validation', f) for f in os.listdir(os.path.join(SOURCE3_DIR, 'validation'))]\n",
        "\n",
        "source3_test_annotations = os.path.join(SOURCE3_DIR, 'test_annotations.json')\n",
        "source3_train_annotations = os.path.join(SOURCE3_DIR, 'train_annotations.json')\n",
        "source3_validation_annotations = os.path.join(SOURCE3_DIR, 'validation_annotations.json')\n",
        "\n",
        "source2_train_pages = [os.path.join(SOURCE2_DIR, 'train', f) for f in os.listdir(os.path.join(SOURCE2_DIR, 'train'))]\n",
        "source2_test_pages = [os.path.join(SOURCE2_DIR, 'test', f) for f in os.listdir(os.path.join(SOURCE2_DIR, 'test'))]\n",
        "source2_validation_pages = [os.path.join(SOURCE2_DIR, 'validation', f) for f in os.listdir(os.path.join(SOURCE2_DIR, 'validation'))]\n",
        "\n",
        "source2_test_annotations = os.path.join(SOURCE2_DIR, 'test_annotations.json')\n",
        "source2_train_annotations = os.path.join(SOURCE2_DIR, 'train_annotations.json')\n",
        "source2_validation_annotations = os.path.join(SOURCE2_DIR, 'validation_annotations.json')\n",
        "\n",
        "train_pages = source3_train_pages + source2_train_pages\n",
        "validation_pages = source3_validation_pages + source2_validation_pages\n",
        "test_pages = source3_test_pages + source2_test_pages"
      ],
      "metadata": {
        "id": "0NinFHmUk569"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_source2_annotation(img_id, json_path):\n",
        "    with open(json_path, 'r') as f:\n",
        "        annotations = json.loads(f.read())\n",
        "\n",
        "    words = annotations[img_id][\"words\"]\n",
        "    lines_bboxes = annotations[img_id][\"lines_bboxes\"]\n",
        "\n",
        "    bboxes = [w['bbox'] for w in words]\n",
        "    transcriptions = [w['transcription'] for w in words]\n",
        "    labels = [0 for i in range(len(words))]\n",
        "    lines_labels = [0 for i in range(len(lines_bboxes))]\n",
        "    return bboxes, labels, lines_bboxes, lines_labels, transcriptions\n",
        "\n",
        "def get_source3_annotation(img_id, json_path):\n",
        "    with open(json_path, 'r') as f:\n",
        "        annotations = json.loads(f.read())\n",
        "    regions_bboxes = []\n",
        "\n",
        "    regions = annotations[img_id][\"regions\"]\n",
        "    for region in regions:\n",
        "      regions_bboxes.append(region[\"region_bbox\"])\n",
        "\n",
        "    regions_contents = annotations[img_id][\"regions_contents\"]\n",
        "\n",
        "    bboxes = []\n",
        "    transcriptions = []\n",
        "    for rc in regions_contents:\n",
        "        bboxes += rc['bboxes']\n",
        "        transcriptions += rc['transcriptions']\n",
        "\n",
        "    labels = [0 for i in range(len(bboxes))]\n",
        "    regions_labels = [0 for i in range(len(regions_bboxes))]\n",
        "    return bboxes, labels, regions_bboxes, regions_labels, transcriptions"
      ],
      "metadata": {
        "id": "IiRDcwXrmIcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symbol_list =[\n",
        "    '.', ',', ';', ':', '!', '?', '-', '_', '(', ')', '[', ']', '{', '}', '<', '>',\n",
        "    '@', '#', '$', '%', '^', '&', '*', '+', '=', '~', '`', '\"', \"'\", '\\\\', '|', '/',\n",
        "    '…', '“', '”', '‘', '’', '«', '»'\n",
        "]\n",
        "\n",
        "def parse_annotations(pages, source2_annotations, source3_annotations, annotations):\n",
        "  for page_path in pages:\n",
        "      page_id = os.path.basename(page_path[:-4])\n",
        "      if SOURCE2_DIR in page_path:\n",
        "          bboxes, labels, lines_bboxes, lines_labels, transcriptions = get_source2_annotation(page_id, source2_annotations)\n",
        "\n",
        "          symbols_indices = [idx for idx in range(len(transcriptions)) if any(sym == transcriptions[idx].strip() for sym in symbol_list)]\n",
        "\n",
        "          bboxes = [bbox for idx, bbox in enumerate(bboxes) if idx not in symbols_indices]\n",
        "          labels = [label for idx, label in enumerate(labels) if idx not in symbols_indices]\n",
        "\n",
        "          if page_id not in [*annotations]:\n",
        "              annotations[page_id] = {\"bboxes\": bboxes,\n",
        "                                      \"labels\": labels,\n",
        "                                      \"lines_bboxes\": lines_bboxes,\n",
        "                                      \"lines_labels\": lines_labels}\n",
        "          else:\n",
        "              raise ValueError(f\"Page with id: {page_id} is already in annotations\")\n",
        "\n",
        "      elif SOURCE3_DIR in page_path:\n",
        "          bboxes, labels, lines_bboxes, lines_labels, transcriptions = get_source3_annotation(page_id, source3_annotations)\n",
        "          symbols_indices = [idx for idx in range(len(transcriptions)) if any(sym == transcriptions[idx].strip() for sym in symbol_list)]\n",
        "\n",
        "          bboxes = [bbox for idx, bbox in enumerate(bboxes) if idx not in symbols_indices]\n",
        "          labels = [label for idx, label in enumerate(labels) if idx not in symbols_indices]\n",
        "\n",
        "          if page_id not in [*annotations]:\n",
        "              annotations[page_id] = {\"bboxes\": bboxes,\n",
        "                                      \"labels\": labels,\n",
        "                                      \"lines_bboxes\": lines_bboxes,\n",
        "                                      \"lines_labels\": lines_labels}\n",
        "          else:\n",
        "              raise ValueError(f\"Page with id: {page_id} is already in annotations\")"
      ],
      "metadata": {
        "id": "SRNlfXtumdeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageDraw\n",
        "def draw_bboxes(image_path, annotations, output_path, line_color=\"green\", word_color=\"blue\"):\n",
        "    image = Image.open(image_path)\n",
        "    draw = ImageDraw.Draw(image)\n",
        "\n",
        "    # Draw line bounding boxes\n",
        "    for line_bbox in annotations[\"lines_bboxes\"]:\n",
        "        draw.rectangle(line_bbox, outline=line_color, width=2)\n",
        "\n",
        "    # Draw word bounding boxes\n",
        "    for bbox in annotations[\"bboxes\"]:\n",
        "        draw.rectangle(bbox, outline=word_color, width=2)\n",
        "\n",
        "    image.save(output_path)\n",
        "    print(f\"Annotated image saved at {output_path}\")"
      ],
      "metadata": {
        "id": "Fy5Gxiccfz5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_annotations = {}\n",
        "validation_annotations = {}\n",
        "test_annotations = {}\n",
        "\n",
        "parse_annotations(train_pages, source2_train_annotations,\n",
        "                  source3_train_annotations, train_annotations)\n",
        "\n",
        "parse_annotations(validation_pages, source2_validation_annotations,\n",
        "                  source3_validation_annotations, validation_annotations)\n",
        "\n",
        "parse_annotations(test_pages, source2_test_annotations,\n",
        "                  source3_test_annotations, test_annotations)"
      ],
      "metadata": {
        "id": "UwPdHeDcmT_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_bboxes(source3_train_pages[0], train_annotations['0265-1'], '/content/source3_example.jpg')\n",
        "draw_bboxes(source2_train_pages[0], train_annotations['c03-007a'], '/content/source2_example.jpg')"
      ],
      "metadata": {
        "id": "hDPf3sK0hLSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "def construct_data_for_yolo(pages, out_dir,\n",
        "                            annotations, bbox_naming,\n",
        "                            label_naming):\n",
        "  for page_path in pages:\n",
        "        page_id = os.path.basename(page_path[:-4])\n",
        "        img_width, img_height = Image.open(page_path).size\n",
        "        shutil.copy(page_path, os.path.join(out_dir, os.path.basename(page_path)))\n",
        "\n",
        "        an_dct = annotations[page_id]\n",
        "        txt_name = os.path.join(out_dir, page_id + '.txt')\n",
        "        with open(txt_name, 'w') as an_file:\n",
        "          for idx in range(len(an_dct[bbox_naming])):\n",
        "\n",
        "            height = an_dct[bbox_naming][idx][3] - an_dct[bbox_naming][idx][1]\n",
        "            width = an_dct[bbox_naming][idx][2] - an_dct[bbox_naming][idx][0]\n",
        "\n",
        "            x_center = (an_dct[bbox_naming][idx][0] + width / 2) / img_width\n",
        "            y_center = (an_dct[bbox_naming][idx][1] + height / 2) / img_height\n",
        "\n",
        "            new_an = [an_dct[label_naming][idx], x_center, y_center, width / img_width, height / img_height]\n",
        "\n",
        "            an_file.write(\" \".join([str(e) for e in new_an]) + \"\\n\")\n"
      ],
      "metadata": {
        "id": "XEd-qVbZngaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_dir = '/content/words_detection/train'\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "construct_data_for_yolo(train_pages, out_dir,\n",
        "                        train_annotations,\n",
        "                        bbox_naming=\"bboxes\",\n",
        "                        label_naming=\"labels\")\n",
        "\n",
        "out_dir = '/content/words_detection/validation'\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "construct_data_for_yolo(validation_pages, out_dir,\n",
        "                        validation_annotations,\n",
        "                        bbox_naming=\"bboxes\",\n",
        "                        label_naming=\"labels\")\n",
        "\n",
        "out_dir = '/content/words_detection/test'\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "construct_data_for_yolo(test_pages, out_dir,\n",
        "                        test_annotations,\n",
        "                        bbox_naming=\"bboxes\",\n",
        "                        label_naming=\"labels\")\n"
      ],
      "metadata": {
        "id": "q1D5S1wKttkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_dir = '/content/lines_detection/train'\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "construct_data_for_yolo(train_pages, out_dir,\n",
        "                        train_annotations,\n",
        "                        bbox_naming=\"lines_bboxes\",\n",
        "                        label_naming=\"lines_labels\")\n",
        "\n",
        "out_dir = '/content/lines_detection/validation'\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "construct_data_for_yolo(validation_pages, out_dir,\n",
        "                        validation_annotations,\n",
        "                        bbox_naming=\"lines_bboxes\",\n",
        "                        label_naming=\"lines_labels\")\n",
        "\n",
        "out_dir = '/content/lines_detection/test'\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "construct_data_for_yolo(test_pages, out_dir,\n",
        "                        test_annotations,\n",
        "                        bbox_naming=\"lines_bboxes\",\n",
        "                        label_naming=\"lines_labels\")"
      ],
      "metadata": {
        "id": "k683dwF0jyB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.make_archive('/content/words_detection', 'zip', '/content/words_detection')"
      ],
      "metadata": {
        "id": "8cZIaKizt7qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.make_archive('/content/lines_detection', 'zip', '/content/lines_detection')"
      ],
      "metadata": {
        "id": "CnXsIq0yvFDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a6pukVndku6G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}