{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hprxLBFekNg"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fK3UrQOIfTxO"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "yolo_model_dir = '/content/yolo_model'\n",
        "os.makedirs(yolo_model_dir, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/Models/words-yolov5/words-yolo.zip', 'r') as f:\n",
        "  f.extractall(yolo_model_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6SY0tzsjnaq"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import shutil\n",
        "\n",
        "SOURCE2_DIR = '/content/SOURCE2/'\n",
        "SOURCE3_DIR = '/content/SOURCE3/'\n",
        "\n",
        "os.makedirs(SOURCE2_DIR, exist_ok=True)\n",
        "os.makedirs(SOURCE3_DIR, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/Datasets/SOURCE2/detection.zip', 'r') as zf:\n",
        "  zf.extractall(SOURCE2_DIR)\n",
        "\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/Datasets/SOURCE3/detection.zip', 'r') as zf:\n",
        "  zf.extractall(SOURCE3_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHqZ6x3Ij1YS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "source3_test_pages = [os.path.join(SOURCE3_DIR, 'test', f) for f in os.listdir(os.path.join(SOURCE3_DIR, 'test'))]\n",
        "\n",
        "source3_test_annotations = os.path.join(SOURCE3_DIR, 'test_annotations.json')\n",
        "\n",
        "source2_test_pages = [os.path.join(SOURCE2_DIR, 'test', f) for f in os.listdir(os.path.join(SOURCE2_DIR, 'test'))]\n",
        "\n",
        "source2_test_annotations = os.path.join(SOURCE2_DIR, 'test_annotations.json')\n",
        "\n",
        "test_pages = source3_test_pages + source2_test_pages\n",
        "random.shuffle(test_pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ODYgN2Yj9dM"
      },
      "outputs": [],
      "source": [
        "def get_source2_transcriptions(img_id, json_path):\n",
        "    with open(json_path, 'r') as f:\n",
        "        contents = json.loads(f.read())\n",
        "\n",
        "    words = contents[img_id][\"words\"]\n",
        "\n",
        "    transcriptions = [w['transcription'] for w in words]\n",
        "\n",
        "    return \" \".join(transcriptions)\n",
        "\n",
        "def get_source3_transcriptions(img_id, json_path):\n",
        "    with open(json_path, 'r') as f:\n",
        "        contents = json.loads(f.read())\n",
        "\n",
        "    regions_contents = contents[img_id][\"regions_contents\"]\n",
        "\n",
        "    transcriptions = []\n",
        "    for rc in regions_contents:\n",
        "        transcriptions += rc['transcriptions']\n",
        "\n",
        "    return \" \".join(transcriptions)\n",
        "\n",
        "def parse_transcriptions(pages, source2_annotations, source3_annotations, annotations):\n",
        "    for page_path in pages:\n",
        "        page_id = os.path.basename(page_path[:-4])\n",
        "        if SOURCE2_DIR in page_path:\n",
        "            transcriptions = get_source2_transcriptions(page_id, source2_annotations)\n",
        "            if page_id not in [*annotations]:\n",
        "                annotations[page_id] = {\"transcriptions\": transcriptions}\n",
        "            else:\n",
        "                raise ValueError(f\"Page with id: {page_id} is already in annotations\")\n",
        "\n",
        "        elif SOURCE3_DIR in page_path:\n",
        "            transcriptions = get_source3_transcriptions(page_id, source3_annotations)\n",
        "            if page_id not in [*annotations]:\n",
        "                annotations[page_id] = {\"transcriptions\": transcriptions}\n",
        "            else:\n",
        "                raise ValueError(f\"Page with id: {page_id} is already in annotations\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq_0wMRjkJ3g"
      },
      "outputs": [],
      "source": [
        "test_annotations = {}\n",
        "parse_transcriptions(test_pages, source2_test_annotations,\n",
        "                  source3_test_annotations, test_annotations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELJ6TlygOgBS"
      },
      "outputs": [],
      "source": [
        "def group_boxes_by_row(boxes, y_margin_ratio=0.35):\n",
        "    sorted_boxes = sorted(boxes, key=lambda box: int(box.xyxy[0][1].cpu().numpy()))\n",
        "\n",
        "    rows = []\n",
        "    current_row = []\n",
        "    prev_y = None\n",
        "\n",
        "    for box in sorted_boxes:\n",
        "        x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
        "        box_height = y2 - y1\n",
        "\n",
        "        y_threshold = box_height * y_margin_ratio\n",
        "\n",
        "        if prev_y is None or abs(y1 - prev_y) > y_threshold:\n",
        "            if current_row:\n",
        "                rows.append(current_row)\n",
        "            current_row = [box]\n",
        "        else:\n",
        "            current_row.append(box)\n",
        "\n",
        "        prev_y = y1\n",
        "\n",
        "    if current_row:\n",
        "        rows.append(current_row)\n",
        "\n",
        "    for row in rows:\n",
        "        row.sort(key=lambda box: int(box.xyxy[0][0].cpu().numpy()))\n",
        "\n",
        "    return [box for row in rows for box in row]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cThkM02nrUM-"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "font_path = \"/content/drive/MyDrive/etc/Roboto-Bold.ttf\"\n",
        "font_size = 24\n",
        "\n",
        "font = ImageFont.truetype(font_path, font_size)\n",
        "color = (128, 0, 128)\n",
        "\n",
        "yolo_model = YOLO('/content/yolo_model/best.pt')\n",
        "yolo_model.overrides['data'] = '/content/yolo_model/yolo_config.yaml'\n",
        "\n",
        "eval_dir = \"/content/eval_results/\"\n",
        "os.makedirs(eval_dir, exist_ok=True)\n",
        "for img_path in test_pages[:50]:\n",
        "    img = Image.open(img_path).convert('L').convert('RGB')\n",
        "    img_np = np.array(img)\n",
        "\n",
        "    results = yolo_model.predict(source=img_np, imgsz=946, device='cpu', max_det=300)\n",
        "\n",
        "\n",
        "    results = results[0]\n",
        "    sorted_boxes = group_boxes_by_row(results.boxes)\n",
        "\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    for i, box in enumerate(sorted_boxes):\n",
        "        x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
        "        draw.rectangle([x1, y1, x2, y2], outline=color, width=3)\n",
        "        draw.text((x1, y1), str(i + 1), fill=color, font=font)\n",
        "\n",
        "    annotated_image_path = os.path.join(eval_dir, os.path.basename(img_path))\n",
        "    img.save(annotated_image_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zmu6zKNpvEGV"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "shutil.make_archive('/content/eval_results' ,'zip', '/content/eval_results')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}