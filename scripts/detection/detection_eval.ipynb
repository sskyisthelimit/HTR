{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hprxLBFekNg"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fK3UrQOIfTxO"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "yolo_model_dir = '/content/yolo_model'\n",
        "os.makedirs(yolo_model_dir, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/Models/words-yolov5/words-yolo.zip', 'r') as f:\n",
        "  f.extractall(yolo_model_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6SY0tzsjnaq"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import shutil\n",
        "\n",
        "SOURCE2_DIR = '/content/SOURCE2/'\n",
        "SOURCE3_DIR = '/content/SOURCE3/'\n",
        "\n",
        "os.makedirs(SOURCE2_DIR, exist_ok=True)\n",
        "os.makedirs(SOURCE3_DIR, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/Datasets/SOURCE2/detection.zip', 'r') as zf:\n",
        "  zf.extractall(SOURCE2_DIR)\n",
        "\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/Datasets/SOURCE3/detection.zip', 'r') as zf:\n",
        "  zf.extractall(SOURCE3_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHqZ6x3Ij1YS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "source3_test_pages = [os.path.join(SOURCE3_DIR, 'test', f) for f in os.listdir(os.path.join(SOURCE3_DIR, 'test'))]\n",
        "\n",
        "source3_test_annotations = os.path.join(SOURCE3_DIR, 'test_annotations.json')\n",
        "\n",
        "source2_test_pages = [os.path.join(SOURCE2_DIR, 'test', f) for f in os.listdir(os.path.join(SOURCE2_DIR, 'test'))]\n",
        "\n",
        "source2_test_annotations = os.path.join(SOURCE2_DIR, 'test_annotations.json')\n",
        "\n",
        "test_pages = source3_test_pages + source2_test_pages\n",
        "random.shuffle(test_pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ODYgN2Yj9dM"
      },
      "outputs": [],
      "source": [
        "def get_source2_transcriptions(img_id, json_path):\n",
        "    with open(json_path, 'r') as f:\n",
        "        contents = json.loads(f.read())\n",
        "\n",
        "    words = contents[img_id][\"words\"]\n",
        "\n",
        "    transcriptions = [w['transcription'] for w in words]\n",
        "\n",
        "    return \" \".join(transcriptions)\n",
        "\n",
        "def get_source3_transcriptions(img_id, json_path):\n",
        "    with open(json_path, 'r') as f:\n",
        "        contents = json.loads(f.read())\n",
        "\n",
        "    regions_contents = contents[img_id][\"regions_contents\"]\n",
        "\n",
        "    transcriptions = []\n",
        "    for rc in regions_contents:\n",
        "        transcriptions += rc['transcriptions']\n",
        "\n",
        "    return \" \".join(transcriptions)\n",
        "\n",
        "def parse_transcriptions(pages, source2_annotations, source3_annotations, annotations):\n",
        "    for page_path in pages:\n",
        "        page_id = os.path.basename(page_path[:-4])\n",
        "        if SOURCE2_DIR in page_path:\n",
        "            transcriptions = get_source2_transcriptions(page_id, source2_annotations)\n",
        "            if page_id not in [*annotations]:\n",
        "                annotations[page_id] = {\"transcriptions\": transcriptions}\n",
        "            else:\n",
        "                raise ValueError(f\"Page with id: {page_id} is already in annotations\")\n",
        "\n",
        "        elif SOURCE3_DIR in page_path:\n",
        "            transcriptions = get_source3_transcriptions(page_id, source3_annotations)\n",
        "            if page_id not in [*annotations]:\n",
        "                annotations[page_id] = {\"transcriptions\": transcriptions}\n",
        "            else:\n",
        "                raise ValueError(f\"Page with id: {page_id} is already in annotations\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq_0wMRjkJ3g"
      },
      "outputs": [],
      "source": [
        "test_annotations = {}\n",
        "parse_transcriptions(test_pages, source2_test_annotations,\n",
        "                  source3_test_annotations, test_annotations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELJ6TlygOgBS"
      },
      "outputs": [],
      "source": [
        "def group_boxes_by_row(boxes, y_margin_ratio=0.4, residual_y_margin_ratio=0.2):\n",
        "    page_heights = [int(box.xyxy[0][3].cpu().numpy()) - int(box.xyxy[0][1].cpu().numpy()) for box in boxes]\n",
        "    avg_page_height = sum(page_heights) / len(page_heights) if len(page_heights) > 0 else 0\n",
        "\n",
        "    sorted_boxes = sorted(boxes, key=lambda box: (int(box.xyxy[0][1].cpu().numpy()) + int(box.xyxy[0][3].cpu().numpy())) / 2)\n",
        "\n",
        "    rows = []\n",
        "    current_row = []\n",
        "    row_midpoints = []\n",
        "\n",
        "    for box in sorted_boxes:\n",
        "        x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
        "        box_mid_y = (y1 + y2) / 2\n",
        "        box_height = y2 - y1\n",
        "        row_midpoint = sum(row_midpoints) / len(row_midpoints) if len(row_midpoints) > 0 else None\n",
        "\n",
        "        if row_midpoint is None or box_mid_y > row_midpoint + avg_page_height * y_margin_ratio:\n",
        "            if current_row:\n",
        "                rows.append(current_row)\n",
        "            current_row = [box]\n",
        "            row_midpoints = [box_mid_y]\n",
        "\n",
        "        else:\n",
        "            current_row.append(box)\n",
        "            row_midpoints.append(box_mid_y)\n",
        "\n",
        "    if current_row:\n",
        "        rows.append(current_row)\n",
        "\n",
        "    for row in rows:\n",
        "        row.sort(key=lambda box: int(box.xyxy[0][0].cpu().numpy()))\n",
        "\n",
        "    return [box for row in rows for box in row]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cThkM02nrUM-"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "font_path = \"/content/drive/MyDrive/etc/Roboto-Bold.ttf\"\n",
        "font_size = 24\n",
        "\n",
        "font = ImageFont.truetype(font_path, font_size)\n",
        "color = (128, 0, 128)\n",
        "\n",
        "yolo_model = YOLO('/content/yolo_model/best.pt')\n",
        "yolo_model.overrides['data'] = '/content/yolo_model/yolo_config.yaml'\n",
        "\n",
        "eval_dir = \"/content/eval_results/\"\n",
        "os.makedirs(eval_dir, exist_ok=True)\n",
        "\n",
        "picked_pages = [ \"0053-2.jpg\",  \"0179-1.jpg\",  \"0290-1.jpg\",  \"0520-2.jpg\",   \"d06-037.jpg\",  \"f07-021a.jpg\",  \"g02-059.jpg\",  \"m02-087.jpg\",  \"p06-030.jpg\",\n",
        "  \"0161-1.jpg\",  \"0191-1.jpg\",  \"0313-1.jpg\",  \"1133-2.jpg\",   \"d06-100.jpg\",  \"f07-069.jpg\",   \"g04-068.jpg\",  \"m02-112.jpg\",  \"p06-042.jpg\",\n",
        "  \"0163-4.jpg\",  \"0203-2.jpg\",  \"0390-2.jpg\",  \"d01-049.jpg\",  \"e06-000.jpg\",  \"f07-081b.jpg\",  \"m01-125.jpg\",  \"n01-031.jpg\",\n",
        "  \"0173-2.jpg\",  \"0239-1.jpg\",  \"0425-4.jpg\",  \"d01-104.jpg\",  \"e06-010.jpg\",  \"f07-084a.jpg\",  \"m01-136.jpg\",  \"n04-139.jpg\",\n",
        "  \"0176-4.jpg\",  \"0242-1.jpg\",  \"0479-4.jpg\",  \"d04-012.jpg\",  \"e06-049.jpg\",  \"f07-092a.jpg\",  \"m02-055.jpg\",  \"n04-213.jpg\",\n",
        "  \"0178-1.jpg\",  \"0247-2.jpg\",  \"0510-2.jpg\",  \"d04-028.jpg\",  \"f04-083.jpg\",  \"g01-004.jpg\",   \"m02-059.jpg\",  \"p02-139.jpg\"\n",
        "]\n",
        "\n",
        "picked_pages_paths = []\n",
        "\n",
        "for page in test_pages:\n",
        "  for picked_page in picked_pages:\n",
        "    if picked_page in page:\n",
        "      picked_pages_paths.append(page)\n",
        "\n",
        "for img_path in picked_pages_paths:\n",
        "    img = Image.open(img_path).convert('L').convert('RGB')\n",
        "    img_np = np.array(img)\n",
        "\n",
        "    results = yolo_model.predict(source=img_np, imgsz=946, device='cuda:0', max_det=300, iou=0.5)\n",
        "\n",
        "    print(os.path.basename(img_path))\n",
        "    results = results[0]\n",
        "    sorted_boxes = group_boxes_by_row(results.boxes)\n",
        "\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    for i, box in enumerate(sorted_boxes):\n",
        "        x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
        "        draw.rectangle([x1, y1, x2, y2], outline=color, width=3)\n",
        "        draw.text((x1, y1), str(i + 1), fill=color, font=font)\n",
        "\n",
        "    annotated_image_path = os.path.join(eval_dir, os.path.basename(img_path))\n",
        "    img.save(annotated_image_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zmu6zKNpvEGV"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "shutil.make_archive('/content/eval_results' ,'zip', '/content/eval_results')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HmMFEj3NOc_4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}